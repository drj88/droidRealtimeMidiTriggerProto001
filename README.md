drj88
https://sorcerer.42web.io
quantum.sorcerer@protonmail.com

droidRealtimeMidiTriggerProto001

https://github.com/drj88/droidRealtimeMidiTriggerProto001


Sandbox-stage of development for real-time midi vocal trigger with simple Autocorrelation-based tracking but realtime performance for Android SDK 23 (targets 33) and up with Oboe NDK 25.1.8937393 via JNI.

from failed Kikcstarter Campaign called PITCHIN (https://www.kickstarter.com/projects/thecodesorcerer/pitchin)

copied from the Kickstarter PITCHIN campaign page...

Story

Hello and welcome to my first and only Kickstarter campaign, "PITCHIN". This write-up is a subset of available information. For more details, please visit the campaign's landing page here:

https://esocodes.com/pitchin

INTRODUCTION & SYNOPSIS

PITCHIN is envisioned to be an Android App that allows you to create music with only your voice. Sing and the app will identify the musical note (pitch) you're singing in real-time. From there, it translates the sung notes into MIDI information which can then trigger an external synthesizer of your choice or the internal PITCHIN synthesizer. Additionally, you will be able to save the data as a midi file as well as the input audio, if you wish. If using the internal PITCHIN synthesizer, you will be able to export the output audio as a file. Instead of using the mic, you'll be able to use pre-recorded soundfiles. Moreover, there will be an audio background track you can load to sing along with from an audio file. If also using the internal synthesizer, with or without a loadable background track, you will NOT need to use headphones. It is only when using an external synthesizer, whether the synth be another app or otherwise, that headphones will be required.

More specifically, it will be a real-time, monophonic harmonic signal to MIDI Android App. In this context, a "monophonic signal" consists of any isolated signal that contains non-stationary sinusoids whose frequencies are harmonically related. In other words, a signal with only singular notes being sung or played at a time, whether on an instrument or with your voice. Such signals are also of the so-called "harmonic oscillator" variety. Harmonic oscillators include stringed instruments, wind instruments, human voices and many others, but excludes most percussion instruments. So, the primary purpose is to have the user utilize their voice but they could just as easily use a guitar, piano or any other "harmonic oscillator", including their voice, as long as only one note is being played or sung at a time.

Such a concept as PITCHIN is nothing new nor innovative, but an Android App that does this in real-time would make it the first of its kind (to my knowledge). Actually, I just released a FREE, OPEN-SOURCE prototype "sandbox" app that does exactly this, so I suppose PITCHIN might be the "second of it's kind" (unless another app comes out for Android before PITCHIN is complete). Anyways, PITCHIN, as envisioned, is something that I'd personally make use of as well as many others throughout the world. Plus, it seems many have been waiting for something like this for a long time on Android. I can make this happen, already have a good start on it, but I need a little help to make it happen in as quickly as possible.

Hence the purpose of this campaign. I'm raising $10,000 to essentially support my basic needs, such as food, gas, various bills and the like so that I can focus all my efforts to seeing PITCHIN become a reality as quickly as possible. As aforementioned, the "sandbox" prototype app I already shared with the world already does the primary requirement, real-time Monphonic-Signal-to-MIDI triggering on Android, but is only the start. The prototype took less than two months to complete with nowhere near full-time effort, so I'm confident PITCHIN will come together quickly. Therefore, a release is set for no later than September, 1st 2022 if this campaign gets funded.

WHO ???

I am Jeremiah "J" Smith, aka "The Code Sorcerer". I have written a great deal of enterprise-level, system-critical software for a wide array of clients over the years, including multi-billion dollar industries, in both private and government sectors. Some of my clients included Dept. of Energy, NASA, Genetics/Genomics (WVU), Logistics (main-hub distribution), tax collection, Martin-Marietta, all sorts, but this will be my very first professional product to the world that is all me and only me. Well, you too of course, should you choose to support this effort, since your input, comments, questions, desires, will be treated as requirements (as long as they are viable and within reason, of course). That is to say, your opinions and thoughts are just as, if not more valuable, than any money amount from any source to me for this project. It truly is a deep, heart-felt desire to make this happen as soon as possible and I want your input and feedback every step of the way.

Here is my personal website resume section with some pictures and little bit more background...

https://esocodes.com/resume

As mentioned, the money I'm asking for is solely for living expenses. I already have the tools I need to complete PITCHIN, and fully intend to do so whether I get funded or not, but the only way I can devote all my efforts to this in 2022, and complete it as fast as possible, is with outside monetary help. Otherwise, I will have to take on another contract and again make software for someone else, leaving very little time to devote to PITCHIN. I'm unmarried, have no children, nor pets, so my living expenses are quite low. Plus, I'm a very frugal person. I don't have a car payment nor house payment, just bills like energy and insurance.

I'm also a little unhappy about getting back into my prior career path, doing contract work or being an employee, because I have never had any kind of ownership nor profit-sharing of any sort in the things I make. I suppose 401k and some other stock options would fall into that category but I'm more interested in direct profit sharing, such as a small percentage of every shipped item and the like. I do not like the stock market either, I think it is too volatile to be relied upon with so many "financial instruments" that can entirely fail without much warning, if any. After helping so many companies make MILLIONS over the years with what I created for them, I'd rather not do that all over again without getting more of a cut. Moreover, I always have to sign a non-compete and non-disclosure agreement or sometimes the work is CLASSIFIED, so I cannot even share with the world, nor use myself, in any way whatsoever, the technologies I have implemented or would in the future, should I "get back on the saddle again" with it all. In a few cases I cannot even mention anything whatsoever or I will get in very deep trouble!

Now I'm at a cross-roads - should I go back to taking on contract/employee work or should I do something else this time around? After thinking on that question extensively I also realized that I've never been able to write the kinds of software I wanted nor in the way I wanted at any point in my programming career. I'm quite passionate about DSP, AI, so many other technologies and techniques, but usually didn't get to utilize them in prior professional settings. I always did exactly what the client wanted and in many cases, even though not required, HOW the client wanted as well, even as an Independent Contractor, as my primary goal was always their satisfaction. I did very well and would do very well again; the pay and various perks were always great, but the type of work, or rather the kinds of software being created, was never completely satisfying for me. One might say, "It was real and it was fun but it wasn't real fun" (little phrase I got from an Uncle). So, I decided to try this campaign in hopes that I could devote all my efforts to PITCHIN and alleviate myself from having to go back into the corporate/government world and their way of doing things.

THE PROOF-OF-CONCEPT PROTOTYPE

Here is a link to a YouTube video in a playlist of others where you can see it in action...

https://www.youtube.com/watch?v=ITeJhIPYhtY&list=PLhmjJqWttvo6qx23rEBWAC7Pn1ucTtkAa&index=3

I apologize for the poor sound quality, I decided on the fly to not use headphones, which the prototype is NOT designed to do, to save some time (kept me from splicing some cords) and also to toy around with what I might have to deal with to complete the sound-cancellation algorithm that will be used in PITCHIN (when using the internal synth and/or backing track and NOT need headphones). If those out there would like videos where you can clearly hear the input/outputs to the prototype as if using headphones, let me know and I will do so. You can alternatively download the source code and build tools and build/deploy to an Android device of your choice and try it yourself. I will not be offering any pre-built APKs of the prototype but may reconsider if urged to do so. Keep in mind that the prototype is simply a proof-of-concept, which it accomplishes, and not terribly important to me, as I am ready to move onto to better things (i.e. - PITCHIN).

And here is the source code which is free and open-source licensed under GPL-2...

https://github.com/esocoder/pitchinSandbox001

The code came together fairly easily and I didn't run into any of the annoying aspects with Android Studio nor Oboe that I did in 2019. Well, almost - Oboe does appear to have a glitch issue (pops in the audio data from Oboe) and will be contacting them about it eventually but nothing of the "show stopping" variety. Since it doesn't affect the current pitch tracking too much, which treats the pops as noise, I haven't paid much attention to it. Plus, the current issue is also very rare, took some time for it to present itself and didn't affect the overall goal of the prototype. As a result of the prototype, I now think it is time to take this proof-of-concept to the next level, which is what the PITCHIN campaign is all about.

NOTE: Please keep in mind that the sandbox prototype, a free, GPL-2 Open-Source Android App, is just a PROTOTYPE and only a PROOF-OF-CONCEPT (i.e. - a "SANDBOX"). That is to say, it is a stepping-stone to complete PITCHIN. Therefore, USE THE SANDBOX APP AT YOUR OWN RISK! It CAN feedback in the current state, so beware. It has NOT been thoroughly tested on anything but emulators and just ONE actual device (a cheapo LG L322DL). I cannot say for sure it will work on your device but any newer phone or tablet should have no problem and many older, Marshmallow or better, will probably work too. Keep in mind though that not all phones, unless relatively new, are going to have adequate low-latency capability, so please check with the specifications of the device to know. It is NOT production ready and Google would immediately reject it should one try to put it on the store, for example. I am not going to be offering any pre-built APKs for this prototype but anyone with the build tools can build it themselves and deploy to any suitable Android device they wish. Note also that the pitch tracking is NOT at all close to what I'd consider "Pro Audio" quality and thus nowhere near what I want in PITCHIN. Although, it might be useful to some out there.

The prototype/sandbox app had one purpose: show if the overall capability is effectively possible, not so much emphasis on pitch detection accuracy, which it does. If you check out the YouTube videos, or build and try yourself, you can see/hear that it isn't too shabby for pitch tracking but definitely not as good as other solutions out there. The pitch algorithm is a make-shift "stock" algorithm, that is a well-known and established algorithm, as place-holder for others in the future. Instead, the purpose was to prove the different pieces required to make something like this would work. Namely, C++ handling of the DSP and low-latency audio input with Oboe, in tandem with Java-based UI and Java-based MIDI, via the JNI, do so in real-time, on Android, which it proves. I had to use Java for the MIDI output portion to allow backwards compatibility with older phones, otherwise I'd do it all in C++. The Java UI portion was simply to save time, but PITCHIN will utilize native C++ and OpenGL ES for the UI instead. The prototype and its existing pitch tracking algorithm could easily be improved significantly as it is now, but since there are far superior solutions of comparable computational complexity, it will be replaced. However, since the prototype app code is now on its own as open-source, it is possible the developer community at large will use it and improve on it themselves, creating a whole other arc of independent development (which would be awesome, by the way). So, we'll see what happens there.

PITCHIN

NOTE: ALL BACKERS AND THOSE WHO PLEDGE WILL GET A FREE COPY AND LIFETIME UPGRADES.

Now to the fun stuff. My ultimate goal is to make a tool for music creation for all ages but also something a professional musician or singer and likewise would use as well. Therefore, the pitch-tracking and real-time aspect is considered secondary to the primary goal of a music creation tool. I want it to be easy, self-explanatory and intuitive as possible that allows one to focus on creating new music without running into problems, distractions, uncertainties and the like as much as can possibly be done in the set time frame. Of course, to accommodate this primary goal, the pitch-tracking must be very good and versatile, as well as all supporting components of the system, all of which will be addressed in detail a bit later. I just want to emphasize first and foremost, that I want this to be a tool for creation and all design ideas I or anyone else come up with is towards the primary goal - music creation.

PITCHIN FEATURES

1. Real-time, or rather 30ms or less response-time on low-latency capable Android devices, processing of non-stationary monophonic harmonic sinusoidal signals from input mic on devices that can also compute the DSP pitch-tracking algorithm faster than additional input data arrives. The term "Fall Out" will be used if new data comes from the mic and DSP processing is still in progress on prior data. All mic inputs will be mono-only - no stereo inputs will be used. If no mono input is available from a particular mic or sensor but stereo/otherwise, PITCHIN will utilize the "lowest" or "left-most" channel instead. PITCHIN will closely track the performance of this process and allow the user to see and know how their device is doing and what to do if Fall Out occur (that is, whether to stop everything it is doing and halt with an error message and red colors or ignore and simply sustain any prior note on MIDI note-on messages. Mechanisms will also be in place to “kill all on MIDI notes” should PITCHIN cannot recover from too many Fall Outs in rapid succession. Such real-time processes will be referred to as "Online processing" or "Online Mode".

2. Instead of using a live mic/sensor as input the user can also choose a pre-recorded file stored on the device, which will allow older phones that cannot meet the criteria of Feature 1 still be usable. If the device cannot meet Feature 1 criteria, processing of files will be done in silence without audio out nor any MIDI channel output either, but show overall processing progress as it ensues, writing MIDI files and/or other output files to the device as one would otherwise be able to do with Feature 1 criteria capability, which will be called "Offline Mode or Offline Processing". That is, it will not function as a Real-time MIDI Trigger, but simply as a “brute-force” “offline” processor, taking as long as the device is capable to complete and put the output in whatever files the user chooses.

3. User-selectable enumerated mic/sensor inputs on the device running the app will be accessible to user for use. NOTE: this would include Bluetooth devices but due to the nature of Bluetooth technology as it is today, there is no way to programmatically improve the latency problems that would occur, which appears to be unavoidable no matter what devices (both Android and any Bluetooth device) is used. So, device inputs will NOT be checked if they're Bluetooth or otherwise suitable, only if they’re an audio input "sensor" of some kind. Additionally, the user can choose a file as described in Feature 2 as an "input source" to "play" or "stream" the file's contents as if the file data was coming in through a regular mic or sensor, which will be a "Online Mode" of processing, and send MIDI out note on/off messages as if it were actually coming in real-time into a mic or sensor input but instead be the file contents. Devices that cannot meet criteria of Feature 1 will simply process the data until it is done without outputting any sound nor MIDI, however, but again provided percentage complete status as described in Feature 2. Additionally, the user can choose to process input files as Feature 1 (if able) or Feature 2, whether Feature 1 criteria is possible on the device or not.

4. The user will be able to load a backing track audio file to play through headphone or speaker output while the user utilizes Online Mode.

5. PITCHIN will have an internal synthesizer to use instead of or in addition to sending MIDI out data. The internal synthesizer output will be played through the speakers or headphones, just as Feature 4 does.

6. If PITCHIN is used without headphones it will take the backing audio track data and/or the internal synthesizer output data to cancel out such bleed-through that gets put "back" into the selected mic/sensor input when operating in Online Mode. PITCHIN will be able to use sound cancellation of those type of output signals from the input signal, if they're present, but will not be able to cancel out any output sounds that PITCHIN itself does not control and generate itself. Therefore, any other app that gets triggered by PITCHIN's MIDI output and generates a sound on its own that goes out of a speaker and into the recording mic/sensor cannot be canceled nor any unexpected sounds that Android OS itself might generate or otherwise from any other unknown source(s). It might be possible Oboe can get a buffer or stream of the final mix output of a speaker, no matter what all is mixed by the OS and all active sound-output apps, to generate the ultimate output signal to a speaker or speakers, but unknown if this is true at this time (but HIGHLY unlikely). There are "shared mode" uses of various devices in oboe, at least for input devices, I am aware of but currently unknown if it would be applicable to output device streams too. If it is true and possible, latency therein would have to be explored. If suitable, it would allow any and all sounds generated by the device PITCHIN is running on, no matter the source of the sounds, to be canceled out of the input sensor/mic and allow headphone free usage in all cases. I feel this possibility is either unlikely to be supported in Oboe or if it is supported, will be of such a bad latency to be useless for effective Online Processing, so it is a preliminary feature that may or may not be possible. Moreover, if the "Shared Mode" is possible in Oboe with output devices, it is likely the "Exclusive Mode" is as well, which would inhibit such bleed-through cancellation capabilities whatsoever. However, if PITCHIN is the only source generating the sound output and the user is not using headphones, whether it's internal synthesizer and/or backing track audio, PITCHIN will be able to cancel out the bleed-through into the sensor and function as if the user were wearing headphones via cancellation process.

7. The internal synth will provide a basic set of 127 “General MIDI” patches or instruments utilizing synth output waveforms based on an open-source C++ synthesizer that will be chosen and integrated at a later time. It has not been chosen as yet but there are candidate codes sources at this time but have not been explored as to their capabilities, sound quality and etc.

8. A configurable metronome will be available to play through the headphones or speakers irregardless of configuration during Online Mode usage. The user will be able to set the tempo as well as time signature, including unusual time signatures such as 7/8 time. That is the “numerator” will be a natural number, excluding zero and up to the value of the “denominator” while the “denominator” value will be numbers that correspond to a quarter-note (4) or an eighth-note (8) only.

9. A configurable “button-palette” will be available to the user where the user can configure various chord types and their inversions to trigger during Online Mode. When pressed during Online Mode, PITCHIN will treat the sung note as the “root” of a chord and the pressed button will cause PITCHIN to trigger all the notes associated with the chord, in the same octave as the “root” note and only do so while pressed. The user will also have palette sets that can be saved and loaded by file name.

10. Basic settings will be alterable by the user and persist between app sessions. Such settings will include whether to use AAudio versus OpenSL ES, various defaults, colors and theme (such as Light and Dark modes) and other settings that will be decided upon at the end of Stage 1 and/or potentially altered throughout all PITCHIN Stages up until final release.

TIME FRAME AND DEADLINES

The campaign will begin on February 1st 2022 and last for 30 days. If successful, the development process, segregated in stages listed below, begins the very next day, March 3th, 2022.

STAGE 1 - "Hashing Stage" - complete by March 7th, 2022

Any and all interested party discussions for desired features, mock-ups of UI, finalize all desired features in production release. Community support forums, etc outside of Kickstarter or existing communication means from me, the developer, to the world at large. I am open to discuss any and all aspects, including models for profit, such as the use of Ads, pay versions, open source or not, etc.

Progress on this will be shared via video, images and other media but no source code will be released during this time.

STAGE 2 - Assembler/C/C++ ONLY & UI - complete by April 1st, 2022

There will be some Java code that still exists, similar to what the current prototype has, to facilitate sending MIDI information in older phones (minimum support will be Marshmallow). However, aside from that all the code will be optimized C/C++ or Assembler code.

The current sandbox prototype utilizes a Java UI layer, as many typical Android apps do but this isn't the fastest nor most cross-platform compatible approach. Finalized UI will be implemented in OpenGL ES 2/3 (possibly with IMGUI or other suitable library) to implement a mostly flat, 2D like interface while being cross-platform compatible (including iOS Metal as it supports OpenGL ES as of 2022).

I like "eye candy" and definitely want a UI that looks very slick and modern and am very open to suggestions or even art/mock-up submissions should you wish to contribute in such a way. Just as long as it isn't overkill and the CPU/GPU usage is low to moderate, I'm game. As of the writing of this campaign Story section, I already have a head-start for this stage.

Progress on this will be shared via video but no source code will be released during this time. There will be test APK's available during this process.

STAGE 3 - Advanced Pitch Detection Algorithm - complete by May 1st, 2022

The core functionality, the pitch tracking, used in the sandbox will be replaced with a far superior but similar in computational-cost to existing pitch tracking. The code will be written to be interchangeable and thus one will be able to "switch out" which pitch tracking they'd like to use (anticipating upgrades/improvements). Currently, utilizing the Fan Chirp Transform and Constant-Q is a very promising algorithm along with gathered log spectrum and pitch salience techniques allows for not just pitch tracking but other capabilities exploitable in future upgrades (such as timbre recognition, polyphony and more). There are others to consider as well and have experience with the vast majority of existing techniques, their capabilities, pitfalls, computational complexity and other need-to-know aspects for implementation. I will outline which ones are available and their properties in Stage 1 and we shall decide.

Progress on this will be shared via video but no source code will be released during this time. There will be test APK's available during this process.

STAGE 4 – Music Creation Emphasis and Testing - complete by June 1st, 2022

All music-creation features such as assignable chords/inversions/scales buttons and any other features we as a community decided to implement that are outstanding will be completed in this stage. This testing stage will be somewhat similar to Stage 1, another "hashing stage" where we test it, discuss, modify and form into the finalized product, as long as any changes are not too extensive. This will encompass any simple changes that can be implemented quickly that will make it an overall better product, such as settings memory, button arrangements, text placement and other “trivial” changes. I will address but ultimately decide if any suggestion is implemented.

There will be test APK's available during this process but no source code will be shared.

STAGE 5 - Publishing – started by August 1st, 2022 completed by September 1st, 2022

Publishing to the Google Play Store and general tasks thereof. This also includes social media marketing, multi-lingual translations and other trivial tasks.

Progress on this will be shared via video but no source code will be released during this time. The finalized product will be available on the Google Play Store.

If for some reason the Google Play Store simply won't agree to publish, there will be a place to get the product on my website instead (will be only one or the other though).

Play Store rejection is unlikely, but possible. For example, suppose another app comes out that does the exact same things, before August 2022. Since 2019, Google simply doesn't want "duplicate", non-unique apps for new submissions (that "reinvent the wheel", as it were), so PITCHIN, or whatever name it ultimately becomes, wouldn't be accessible there. Therefore, if such an event takes place, I will ensure there is a way to still get it.

IMITONE

Many of you out there have already invested in another campaign that is essentially what PITCHIN will be, which promised both Android and iOS apps (if I recall), in addition to plugins & etc called the "Imitone Mind to Melody" campaign here on Kickstarter. Yet, as time pushes onto almost a decade later, I am unaware of any mobile versions, which is the emphasis of my efforts here. I already have a FREE and OPEN-SOURCE prototype "sandbox" Android App that proves it is possible and you can try it right now for no cost. I did it in less than two months, at end of 2021 around Thanksgiving and Christmas. Granted, it does NOT track nearly as well as Imitone can, nor many other pitch-to-midi solutions that now exist, but is still the first of its kind (that I am aware of). The purpose of the prototype was more to test the different components of such an app working together to ensure it is in fact possible, which it does, but little emphasis on pitch-tracking accuracy. This is because the Android sound system has traditionally been problematic and far less than capable of low-latency until fairly recently. Thus, it is only sandbox/prototype and NOT ready for prime-time. Nonetheless, improving or replacing the pitch-tracking algorithm will be very straight-forward for me or any other competent developer(s). Now that it is open-source, it is certainly possible the developer community will utilize it and create something even better, or entirely unexpected, as time goes on. By the way, if any other developers would like to expand on that source code, by all means proceed, that would be AWESOME!

Being that I personally want an Android App that I sing into and trigger a synthesizer, I would sometimes check on Imitone occasionally over the years among other potentials. I did not back Evan's project but had considered doing so. However, when the demo executable I attempted immediately crashed I decided not to (it wouldn’t even start). Thus, I do not follow it closely. I apologize if any of my statements on Imitone are inaccurate or incorrect but I do not believe they are. I did recently take the time to read what others have been posting about Imitone over the years. It seems some are not happy whatsoever with the progress, as many deliverables are yet to be fulfilled among other aspects. I too think the situation is unacceptable. There are and have been suitable algorithms for high-quality pitch-tracking for decades, there is no reason to "re-invent the wheel", as it were. Evan has often referred to the pitch-tracking aspect of Imitone, ascribing it taking a great deal of development time, in additional to it being apparently unique and innovate, but it perplexes me why he decided to do such a thing in the first place. Why not use existing techniques? Perhaps he wanted to make an algorithm from scratch, something entirely new, which I can respect, in hopes of a patent maybe, but when tasked with making a professional product, via other peoples' money and on a time schedule, it would NOT be a good choice. Especially for such a complicated field such as DSP (Digital Signal Processing)! I do not know the reason(s) for many of his other statements either nor do I really care to at this point. It is simply NOT the way I feel he should have handled his Imitone project and it is absolutely not the way I am going to go about PITCHIN.

For those of you out there entirely disenchanted with the Imitone campaign, and understandably so, please do not associate those bad experiences with this campaign. I'm a professional with extensive experience and excellent track record for getting the job done right the first time and have done so for some pretty “heavy weights” as it were. I'm going to treat all my backers collectively as if they are my new client and job and thus approach the situation as I always have in any professional setting of the past. My prior clients will tell you, at least those that are still around and accessible, I am outstanding at what I do and I get the job done right, the first time.
Risks and challenges

PITCHIN is considered a DSP (Digital Signal Processing) app which is one of the most difficult to implement. The algorithms and concepts themselves are fairly complex and there is always a balance between what can be done in the fastest way possible and what it does. A great deal of testing, "sandboxing" / prototyping, and other "extreme programming" techniques (at least how I approach) is time consuming but delivers solid results. Expected time frames can be longer than initially anticipated, many algorithms in available papers are mathematical, only equations and such, without any example source code in MATLAB or Python and thus must be "converted" (implemented) in code from scratch. Hardware and other device-level situations change (new devices, operating system update changes which sometimes break existing code, etc)... It is a complicated landscape, but such things are my specialty. Most of the algorithms and techniques are already worked out, well established and proven. In the main, it will simply be getting them to run fast enough (not just with pitch detection/tracking, but resampling, built-in synth, etc)